# ¿QUÉ, PARA QUÉ Y CÓMO VAMOS A EVALUAR? {#COMP1}

<center>![](images/comp1.png){width=60%}</center>

En este componente debemos considerar un panorama general de los aspectos esenciales del desarrollo de una prueba, los cuales nos permitirán responder las cuestiones básicas ¿qué voy a evaluar? ¿para qué voy a evaluar? y, ¿cómo voy a evaluar?, todo esto nos servirá como un marco de referencia para que los componentes posteriores que conforman este manual trabajen en conjunto en la tarea de respaldar las afirmaciones que hagamos de los resultados de los alumnos observados en la prueba, buscando siempre que exista una alineación y coherencia entre las distintas fases del proceso de desarrollo de la prueba, con respecto a los usos e interpretaciones que pretendemos hacer de los resultados del examen.

Los pasos que conforman este componente son los siguientes según el @INEE2019 y @Lane2016:

## ¿Qué voy a medir?
Debemos definir que habilidad o conocimiento que queremos evaluar, aclarando desde qué modelo teórico o educativo será abordado, por ejemplo, si nuestra prueba medirá comprensión lectora, ese sería nuestro [constructo](#constructo) y podríamos especificar que lo abordaremos basándonos en el marco educativo de la prueba de competencia lectora de PISA 2018 [@PISA2018]).

## ¿Para qué voy a medir?
Tenemos que definir el propósito de la evaluación, puesto que es el que guiará la forma en la que se desarrollarán los componentes posteriores, por lo que siempre hay que tenerlo presente. Por ejemplo, nuestro examen de comprensión lectora puede tener como propósito realizar una evaluación diagnóstica de la habilidad de comprensión lectora de los alumnos de sexto semestre de la carrera de Psicología a fin de contar con elementos que permitan al docente ajustar los contenidos que se abordarán durante el semestre. 

## ¿A quién voy a evaluar?
Tenemos que especificar claramente las características de la población objetivo y el contexto, con el fin de enfatizar que las inferencias o interpretaciones que se hagan de los resultados de la prueba son válidas para esa población y contexto en específico. Siguiendo con el ejemplo anterior nuestra población serían los estudiantes de sexto semestre de la licenciatura en Psicología del turno matutino y vespertino de la Facultad de Psicología de la UNAM, facultad que se encuentra en la Ciudad de México. 
Este aspecto es importante porque las inferencias que se realicen solo serán válidas a esta población, si se quisiera aplicar este instrumento en estudiantes de sexto semestre de otro contexto tendríamos que hacer de nuevo una revisión exhaustiva de todo el instrumento y de sus [parámetros psicométricos](#param).

## ¿Cuáles serán las interpretaciones para los usos previstos de la prueba?
Tenemos que especificar si las interpretaciones que haremos de los resultados de la prueba serán con referencia a normas o a criterios establecidos, en ambas lo que hacemos es comparar la evaluación con un referente, en el caso de una evaluación referente a [normas  o normativo](#norma) el referente de comparación son el conjunto de  sustentantes que respondieron la prueba, mientras que en una evaluación referente a [criterios o criterial](#criterio), se interpretan los resultados a partir de un estándar o criterio, por lo que hay que señalar de manera precisa cómo se hará la interpretación de los resultados. Un ejemplo de un examen que sus resultados se interpretan a partir de la norma sería si nuestro examen de comprensión lectora nos sirve para ordenar a los alumnos de menor a mayor puntaje y así a los primeros diez lugares les damos una beca para un curso sobre redacción de cuentos y ensayos; mientras que un examen criterial sería aquel en el que nuestras interpretaciones de los resultados se basan en criterios de desempeño como “básico”, “competente” y “sobresaliente” y a partir de esos resultados establecemos que los que tengan un desempeño básico en comprensión lectora irán a un curso de regularización. 

Como podemos notar las interpretaciones de los resultados no pueden separarse de sus usos, es decir, de las decisiones que se tomarán a partir de ellos, por lo que en este paso es fundamental precisar cuáles serán los usos válidos y no válidos de los resultados del instrumento. En el ejemplo anterior podemos especificar que el examen tendrá un uso para el otorgamiento de becas y que los usos inválidos serían usar los resultados para aprobar o reprobar alumnos en un curso. En el otro ejemplo los usos previstos serían el de asignar a los estudiantes a un curso de regularización y como usos inválidos podemos establecer usar los resultados para asignar calificaciones finales de un curso.

Tenemos que ser muy claros en los usos válidos y no válidos para evitar que se hagan malos usos de la prueba que corrompan la percepción que se tiene de la evaluación y por ende dejen de ser válidas nuestras interpretaciones de la prueba. 

## ¿Cuál será el tipo de instrumento y el formato de los reactivos?
Con base en los pasos anteriores tenemos que decidir qué tipo de instrumento desarrollaremos en función del tiempo y recursos con los que contamos, si va a ser una [prueba objetiva](#examen) o un [cuestionario](#cuestionario), si las repuestas que se solicitarán serán de selección o libres y también debemos especificar si la administración del instrumento está planeada para ser en lápiz y papel o en computadora. Por ejemplo, para una prueba de comprensión lectora podemos hacer uso de una prueba objetiva con reactivos de selección múltiple que contarán con cuatro opciones de respuesta donde solo una será la repuesta correcta y la aplicaremos en formato de lápiz y papel.

:::nota 
Este manual se enfocará en el proceso referente a pruebas objetivas con reactivos de selección múltiple. Sin embargo, es importante que el lector sepa de la posibilidad de utilizar otras opciones, las cuales puede consultar en libros como el de @Lane2016.
:::

## ¿Qué procedimiento seguiremos para saber si nuestro instrumento es válido, confiable y que nuestros reactivos se comportan de manera adecuada?

Aquí se hace referencia al modelo de medición de la prueba, es decir, debemos hacer explicita la manera en que obtendremos los parámetros de los reactivos en términos de su [dificultad](#dificultad) (cantidad de sustentantes que responden correctamente el reactivo) y su [discriminación](#discriminacion) (si el reactivo diferencia entre los sustentantes que saben y los que no saben), la confiabilidad de la medición (precisión del instrumento) y la validez de la evaluación (inferencias precisas de los resultados de la evaluación). También es importante determinar desde este momento si llevaremos a cabo análisis de [sesgos](#sesgo) para asegurar la justicia en la evaluación, es decir, que los reactivos no actúen de manera diferente en las subpoblaciones en términos de sexo, religión, etnia, nacionalidad, idioma, etc. 

En este paso también debemos establecer los [criterios de calidad de los reactivos](#calidad) e instrumentos, en otras palabras, debemos determinar las [propiedades estadísticas](#prop-estad) deseadas para determinar que un reactivo es adecuado o no y también si el instrumento está funcionando o no de acuerdo con nuestro propósito.

Por ejemplo, podemos decidir que la validez del contenido de la prueba la determinaremos por medio de un grupo de expertos que revisarán los reactivos, la confiabilidad la determinaremos a través de la [consistencia interna](#consistencia) del instrumento usando el coeficiente [Alpha de Cronbach](#alpha) y con el método de [pruebas paralelas](#paralel), dado que desarrollaremos dos versiones del examen; con respecto a las propiedades estadísticas podemos determinar que la confiabilidad será mayor a 0.8 con un nivel de significancia de 0.05.

## ¿Cuántos reactivos tendrá nuestra prueba y como estará organizada?
El determinar la longitud del instrumento depende del propósito de la evaluación, de los recursos y tiempo disponible y de las interpretaciones y usos previstos de los resultados, también tenemos que señalar si habrá varias versiones de una misma prueba, y cómo se organizará el instrumento en sus diferentes dimensiones. Por ejemplo, la prueba de comprensión lectora aplicada a alumnos de sexto semestre contará con 60 reactivos, 20 de la [dimensión](#dimension) de localización de información, 20 de comprensión y 20 de evaluación y reflexión que en conjunto serán resueltos en un tiempo de 2 horas. 

## ¿Cómo calificaremos la prueba?
En este apartado tenemos que retomar lo que se establecimos en el paso 1.4 sobre si nuestras interpretaciones de los resultados estarán basadas en la norma o en criterios de desempeño, pero tenemos que ser específicos en la forma en que calificaremos la prueba, señalando si los reactivos solo tienen una respuesta correcta y las demás son los [distractores](#distractores) o si hay reactivos con respuestas parcialmente correctas; de igual manera se especifica si todos los reactivos tienen el mismo peso en la [calificación](#calificacion) o si una dimensión del instrumento tiene un peso mayor.  Por ejemplo, nuestro examen de comprensión lectora que cuenta con 60 reactivos de respuesta correcta única se calificará otorgando un punto a cada reactivo y todas las dimensiones tienen el mismo valor para la calificación final del examen. 

## Otras características importantes a considerar
Definir los grupos de expertos que participaran en el desarrollo de cada componente, por ejemplo, en la elaboración de las especificaciones, otros en el desarrollo de reactivos y otros en la revisión de los reactivos elaborados, especificando los procedimientos de selección y sus cualificaciones. También es importante definir desde este momento si se realizaran adaptaciones al instrumento para los sustentantes con discapacidades o que hablen otro idioma.

Como nos podemos dar cuenta en la totalidad de este componente definimos de manera clara los aspectos básicos de nuestra prueba y determinamos de manera general los procedimientos que seguiremos en los componentes posteriores de manera más detallada.


:::evidencia
**Evidencia documental:** 
En este componente podemos obtener como evidencias la ficha técnica de la prueba, la información académica y profesional de los expertos que nos apoyarán en los componentes posteriores y el protocolo de seguridad de la información.
:::

:::seguridad
**Seguridad:**
Hay que tener en cuenta el resguardo de la información que se construya en este componente, por lo que es necesario establecer protocolos de seguridad y hacerlos explícitos a los grupos de expertos que nos apoyarán en las siguientes fases de desarrollo.
:::

:::aera
**Estándar 4.0**
*“Las pruebas y programas de evaluación deben diseñarse y desarrollarse de una manera que respalde la validez de las interpretaciones de los puntajes de la prueba para sus usos previstos. Los desarrolladores y editores de pruebas deben documentar las medidas tomadas durante el proceso y desarrollo de la prueba para proporcionar evidencia de imparcialidad, confiabilidad y validez para los usos previstos para individuos en la población prevista de individuos examinados”*

[@AERA2018, p.96]
:::

:::aera
**Estándar 1.8** 
*“La composición de cualquier muestra de examinandos de la cual se obtiene evidencia de validación debe describirse con tanto detalle como sea práctico y aceptable, incluidas características sociodemográficas y de desarrollo relevantes*

@AERA2018, p.27]
:::

:::quiz

[**¿Por qué es necesario establecer los usos inválidos de la prueba?**]


:::

:::quiz

[**¿Qué función tiene el propósito de la evaluación?**]

:::